- hosts: storage
  name: Prepare Debian RPi node for glusterfs cluster-up
  tasks:
    - name: Run full upgrade
      ansible.builtin.apt:
        upgrade: full
        update_cache: true
    - name: Install htop, kitty-terminfo, and lvm2
      ansible.builtin.apt:
        name:
          - htop
          - kitty-terminfo
          - lvm2
        state: present
    # https://forums.raspberrypi.com/viewtopic.php?t=245931
    - name: Blacklist UAS for flaky SABRENT devices
      ansible.builtin.copy:
        content: |
          usb-storage.quirks=152d:1561:u
        dest: /etc/default/raspi-extra-cmdline
        mode: 0644
      register: cmdline
    - name: Regenerate initramfs
      ansible.builtin.command:
        cmd: update-initramfs -u
      when: cmdline.changed
    - name: Set hostname
      ansible.builtin.copy:
        content: "{{ inventory_hostname }}"
        dest: /etc/hostname
        mode: 0644
      register: hostname
    - name: Set hosts
      ansible.builtin.lineinfile:
        line: "127.0.1.1 {{ inventory_hostname }}"
        mode: 0644
        path: /etc/hosts
    - name: Deploy sshd config
      ansible.builtin.copy:
        src: files/sshd_config
        dest: /etc/ssh/sshd_config
        mode: 0644
      notify:
        - Restart sshd
    - name: Ensure .ssh dir exists
      ansible.builtin.file:
        path: ~/.ssh
        state: directory
        mode: 0755
    - name: Deploy authorized_keys
      ansible.builtin.copy:
        src: files/authorized_keys
        dest: ~/.ssh/authorized_keys
        mode: 0600
    - name: Check if reboot is required for package upgrade
      register: reboot_required_file
      ansible.builtin.stat:
        path: /var/run/reboot-required
    - name: Reboot host
      ansible.builtin.reboot:
        msg: Reboot initiated by Ansible
        connect_timeout: 5
        reboot_timeout: 600
        pre_reboot_delay: 0
        post_reboot_delay: 60
        test_command: uptime
      when: reboot_required_file.stat.exists or cmdline.changed or hostname.changed
    - name: Deploy SSD udev rule
      ansible.builtin.copy:
        src: files/60-ssd-scheduler.rules
        dest: /etc/udev/rules.d/60-ssd-scheduler.rules
        mode: 0644
      notify:
        - Reload udev rules
    - name: Install glusterfs
      ansible.builtin.apt:
        name: glusterfs-server
        state: present
        update_cache: true
    - name: Create LVM volume groups
      with_items:
        - /dev/sda
        - /dev/sdb
      community.general.lvg:
        pvs: "{{ item }}"
        vg: "data.{{ item | basename }}"
    - name: Create LVM thinpools
      with_items:
        - data.sda
        - data.sdb
      community.general.lvol:
        thinpool: "{{ item }}-pool"
        size: 450G
        vg: "{{ item }}"
    - name: Create LVM bricks
      with_items:
        - data.sda
        - data.sdb
      community.general.lvol:
        lv: brick
        size: 450G
        thinpool: "{{ item }}-pool"
        vg: "{{ item }}"
    - name: Set up ext4 on LVM bricks
      with_items:
        - /dev/data.sda/brick
        - /dev/data.sdb/brick
      community.general.filesystem:
        dev: "{{ item }}"
        fstype: ext4
    - name: Create mount points for LVM bricks
      with_items:
        - sda
        - sdb
      ansible.posix.mount:
        backup: true
        boot: true
        fstype: ext4
        path: "/data/{{ item }}"
        src: "/dev/data.{{ item }}/brick"
        state: mounted
    - name: Enable & Start GlusterFS server
      ansible.builtin.systemd:
        name: glusterd
        enabled: true
        state: started
  handlers:
    - name: Reload udev rules
      become: true
      become_user: root
      ansible.builtin.command:
        cmd: udevadm control --reload-rules
    - name: Restart sshd
      ansible.builtin.systemd:
        name: sshd.service
        enabled: true
        state: restarted
